# backend/app/llm_service.py

from __future__ import annotations

import os
from typing import Dict, Any, List, Tuple

try:
    from openai import OpenAI  # official SDK
except Exception as e:
    OpenAI = None  # type: ignore


# -----------------------------
# Config
# -----------------------------
DEFAULT_MODEL = os.getenv("OPENAI_MODEL", "gpt-5.2")  # change if needed
MAX_BULLETS = int(os.getenv("LLM_MAX_BULLETS", "6"))


# -----------------------------
# Heuristic reasons (no LLM)
# -----------------------------
def _top_reasons_from_features(features: Dict[str, Any], risk_score: float) -> List[str]:
    """
    Turn numeric features into human hints.
    This helps the LLM explain using concrete evidence.
    """
    f = features or {}
    reasons: List[str] = []

    def add(msg: str):
        if msg and msg not in reasons:
            reasons.append(msg)

    # Strong phishing signals
    if f.get("has_ip", 0) == 1:
        add("The URL uses an IP address instead of a normal domain (common phishing pattern).")
    if f.get("has_punycode", 0) == 1:
        add("The domain appears to use punycode (xn--), which can be used for look-alike domains.")
    if f.get("has_at_symbol", 0) == 1 or f.get("num_at", 0) > 0:
        add("The URL contains '@', which can hide the real destination.")
    if f.get("double_slash_after_scheme", 0) == 1:
        add("The URL contains '//' after the domain, which can be used to obscure redirect paths.")
    if f.get("has_http_in_path", 0) == 1 or f.get("http_count", 0) >= 2:
        add("The URL contains multiple 'http' tokens, which can be used to confuse users.")
    if f.get("is_shortener", 0) == 1:
        add("This looks like a shortened URL, which hides the final destination.")
    if f.get("is_suspicious_tld", 0) == 1:
        add("The domain uses a higher-risk TLD that is often abused for phishing.")

    # Structural / obfuscation patterns
    if f.get("url_length", 0) >= 75:
        add("The URL is unusually long, which is often used to hide malicious parts.")
    if f.get("digit_ratio", 0) >= 0.25 or f.get("num_digits", 0) >= 15:
        add("The URL contains many digits, which can indicate autogenerated or obfuscated links.")
    if f.get("num_hyphens", 0) >= 4:
        add("The URL has many hyphens, often seen in fake look-alike domains.")
    if f.get("subdomain_levels", 0) >= 3:
        add("The URL has many subdomains, which can mimic trusted sites (e.g., login.bank.com.evil.com).")
    if f.get("num_question", 0) >= 1 and f.get("num_ampersand", 0) >= 3:
        add("The URL has a heavy query string with many parameters, which can be suspicious.")
    if f.get("url_entropy", 0) >= 4.2:
        add("The URL looks highly random/encoded (high entropy), which can indicate obfuscation.")

    # Credential bait tokens
    if f.get("sensitive_token_hits", 0) >= 1:
        add("The URL contains login/verify/account-style keywords, commonly used in phishing.")
    if f.get("brand_word_hits", 0) >= 1:
        add("The URL contains brand-related words that attackers often use for impersonation.")

    # Security signal (weak)
    if f.get("is_https", 0) == 0:
        add("The URL is not using HTTPS (no secure transport).")

    # Add a risk-score summary
    if risk_score >= 0.85:
        add("Overall risk score is very high — treat this link as unsafe.")
    elif risk_score >= 0.65:
        add("Overall risk score is high — proceed with extreme caution.")
    elif risk_score >= 0.45:
        add("Overall risk score is medium — verify the sender and destination carefully.")
    else:
        add("Overall risk score is low — still be cautious with unknown links.")

    return reasons[:MAX_BULLETS]


def _fallback_explanation(url: str, label: str, risk_score: float, features: Dict[str, Any]) -> str:
    reasons = _top_reasons_from_features(features, risk_score)
    bullets = "\n".join([f"- {r}" for r in reasons])
    return (
        f"Result: **{label.upper()}** (risk score: {risk_score:.2f})\n\n"
        f"Why:\n{bullets}\n\n"
        f"Safety tip: If this came from an unknown sender, avoid entering passwords/OTP and verify the domain manually."
    )


# -----------------------------
# LLM Explanation
# -----------------------------
def generate_explanation(
    url: str,
    label: str,
    risk_score: float,
    features: Dict[str, Any],
) -> str:
    """
    Generates a short, user-friendly explanation using OpenAI.
    If OPENAI_API_KEY is missing or SDK isn't installed, returns a deterministic fallback.
    """
    api_key = os.getenv("OPENAI_API_KEY")
    if OpenAI is None or not api_key:
        return _fallback_explanation(url, label, risk_score, features)

    client = OpenAI(api_key=api_key)

    reasons = _top_reasons_from_features(features, risk_score)

    # Make the output consistent & safe for end users
    instructions = (
        "You are a security assistant. Explain phishing-risk results clearly and briefly. "
        "Do NOT re-predict. Use ONLY the provided model result and features. "
        "Output format:\n"
        "1) One-line verdict.\n"
        "2) 3–6 bullet reasons.\n"
        "3) 2 short safety actions.\n"
        "No extra sections."
    )

    # Keep the prompt grounded
    input_text = (
        f"URL: {url}\n"
        f"Model label: {label}\n"
        f"Risk score (0-1): {risk_score}\n"
        f"Key reasons (derived from features):\n"
        + "\n".join([f"- {r}" for r in reasons])
        + "\n\n"
        "Write the explanation now."
    )

    try:
        # Official Responses API (recommended in latest SDK docs)
        resp = client.responses.create(
            model=DEFAULT_MODEL,
            instructions=instructions,
            input=input_text,
        )
        text = (resp.output_text or "").strip()
        return text if text else _fallback_explanation(url, label, risk_score, features)
    except Exception:
        return _fallback_explanation(url, label, risk_score, features)